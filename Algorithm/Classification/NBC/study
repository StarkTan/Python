朴素贝叶斯分类算法(NBC)
公式推导
  1.概率乘法法则
    P(A,B)=P(A)P(B|A)=P(B,A)=P(B)P(A|B)
    P(A,B)：A，B事件联合出现的概率
    P(A)：A出现的概率
    P(B|A): A出现的情况下B出现的概率
    当A，B为独立事件时：P(A,B)=P(A)P(B)
    多个事件时：P(A,B1,B2,B3)=P(A)P(B1|A)P(B2|A,B1)P(B3|A,B1,B2)
  2.概率加法公式
    P(A)=∑P(A,Bi)=∑P(A|Bi)P(Bi)
  3.朴素贝叶斯分类
    特点：
      统计学模型：基于贝叶斯原理（后验概率 = 先验概率 * 似然度 / 标准化常量）的分类器
      假设前提：给定任一类别，各个属性之间相互独立
      分类性能：与决策树和部分神经网络分类模型相当
    原理：
      给定一个包含输入和输出的训练集, 每个样本表示为n维向量X = (x1, x2, …, xn)，假设有 m 个类别, 即C1, C2, …, Cm；
      基于贝叶斯原理有 P(Ci|X) = P(X|Ci)*P(Ci)/P(X)
      因为P(X)对C的所有类别恒定，所以 P(Ci|X) ∝ P(X|Ci)*P(Ci)
      P(Ci|X)：朴素贝叶斯分类器的目标是最大化后验概率。
      P(Ci)：先验概率，可从训练集中计算： si/s；
      si为训练集中类别为Ci的样本数，s为训练集的总样本数。
      P(X)：标准化常量。
      P(X|Ci)：似然度
    平滑
      计算每个属性联合概率的过程中出现0值，需要使用平滑系数，计算方法：
      先验概率平滑：分子 = 原分子 + 平滑系数，分母 = 原分子 + 训练数据的分类总数 * 平滑系数
      似然度平滑：分子 = 原分子 + 平滑系数，分母 = 原分子 + 指定属性种类数量 * 平滑系数
      