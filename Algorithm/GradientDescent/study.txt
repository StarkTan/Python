梯度下降算法
    参考网站：
        https://www.jianshu.com/p/c7e642877b0e
梯度下降法和最小二乘法的区别
    参考网站
        https://blog.csdn.net/suibianshen2012/article/details/51532003
   相同
　　1.本质相同：两种方法都是在给定已知数据的前提下对dependent variables算出出一个一般性的估值函数。然后对给定新数据的dependent variables进行估算。
　　2.目标相同：都是在已知数据的框架内，使得估算值与实际值的总平方差尽量更小（事实上未必一定要使用平方）
    不同
　　1.实现方法和结果不同：
        最小二乘法是直接对平方差求导找出全局最小，是非迭代法。
        而梯度下降法是一种迭代法，先给定一个预期，然后向平方差下降最快的方向调整预期，在若干次迭代之后找到局部最小。
   梯度下降法的缺点是到最小点的时候收敛速度变慢，并且对初始点的选择极为敏感，其改进大多是在这两方面下功夫。